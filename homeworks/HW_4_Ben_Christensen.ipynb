{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ben Christensen\n",
    "### Homework 4\n",
    "### Predicting Titanic Survivors\n",
    "### March 8, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from collections import Counter\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv(\"train_titanic.csv\")\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age has a significant amount of missing observations (20%) and Cabin is missing most of its observations (77%). I will need to address this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my training set I drop the variables:\n",
    "* Passenger ID\n",
    "* Cabin\n",
    "\n",
    "Passenger ID was created by Kaggle so it shouldn't be useful here. For the variable \"name\", I considered checking for each individual, how many other people aboard the Titanic have the same last name, but that would mostly be a proxy for how many relatives are aboard. We already have two variables that measure that: sbisp and parch. Instead, perhaps the alphabetical order of the last name may have been used in deciding where to house passengers. So I create a variable for the first letter of the last name. Also, before dropping the \"Cabin\" variable, I use it to create the variable \"Deck\" and \"Odd\". I think passengers on a lower deck have a lower chance of survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed a correlation in the data between ticket number and last name. It seems the ticket number may be close for those who live together and maybe even for those who are near to each other. For this reason, I create a new ticket number variable which may gather some of the information missing from the \"Cabin\" variable because so many of its observations are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Clean_Data(labels, filename=\"train_titanic.csv\", test=False):\n",
    "    \"\"\"Prepare data for use in model\n",
    "    \n",
    "    Parameters:\n",
    "        filename(string): name of file to import data from\n",
    "        labels(list): list of strings of labels to drop from dataset\n",
    "        test(bool): Whether or not we are cleaning the final testing data\n",
    "    \"\"\"\n",
    "    X = pd.read_csv(filename)\n",
    "    if test != True:\n",
    "        y = X['Survived']\n",
    "    #Create a new variable named Deck based on which deck the cabin was on\n",
    "    X[\"Deck\"] = X[\"Cabin\"].astype(str).str[0]\n",
    "    X = X.fillna(value={\"Age\": -1, \"Deck\": -1, \"Ticket\":-1})\n",
    "    \n",
    "    #Create variable for first letter of last name\n",
    "    for i, name in enumerate(X[\"Name\"].values):\n",
    "        last_name = name.split(sep=\",\")[0]\n",
    "        X.set_value(i, \"First_Letter\", last_name[0])\n",
    "        \n",
    "    #I explain the creation of this new variable below under the graph\n",
    "    X[\"Child\"] = 1*(X[\"Age\"].notnull() & (X[\"Age\"] < 16))\n",
    "    for i, age in enumerate(X[\"Age\"].values):\n",
    "        if age == -1:\n",
    "            X.set_value(i, \"Child\", -1)\n",
    "            \n",
    "    #Here we split the ticket number into strings and numbers\n",
    "    for i, ticket in enumerate(X[\"Ticket\"].values):\n",
    "        split_ticket = ticket.split()\n",
    "        first = split_ticket[0]\n",
    "        last = split_ticket[-1]\n",
    "        #Create ticket number variable\n",
    "        if last.isdigit():\n",
    "            X.set_value(i, \"Ticket_num\", int(last))\n",
    "        #create ticket name variable\n",
    "        if first.isdigit() == False:\n",
    "            X.set_value(i, \"Ticket_name\", first)\n",
    "\n",
    "    #Drop desired variables           \n",
    "    X = X.drop(labels=labels, axis=1)\n",
    "    X = X.fillna(value={\"Ticket_num\": -1, \"Ticket_name\": -1, \"Fare\":-1})\n",
    "    \n",
    "    #Turn categorical variables into numerical dummy variables for use in models\n",
    "    for label in [\"Embarked\", \"Sex\", \"Deck\", \"First_Letter\", \"Ticket_name\"]:   \n",
    "        X[label] = X[label].astype('category')\n",
    "        X[label] = X[label].cat.codes\n",
    "    \n",
    "    if test != True:\n",
    "        return X, y\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=['Survived', \"Name\", \"PassengerId\", \"Cabin\", \"Ticket\"]\n",
    "X, y = Clean_Data(labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyY8/L9TC0VsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ee4e7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(0, 92, 4)\n",
    "plt.hist(X[\"Age\"].values, bins=bins, edgecolor=\"k\")\n",
    "plt.xticks(bins)\n",
    "plt.title(\"Ages of Passengers Aboard Titanic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't very many children aboard the Titanic in the training sample. This graph gives a good feel for the distribution of children. In the function above, I create a variable \"child\" for every passenger under the age of 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "I decided to try a Random Forest first to see how that does. A decision tree seems to me a natural way to understand this problem. Most of the variables are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we split our training set into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [1000, 2500, 5000]\n",
    "max_depth = [1, 3, 5, 10]\n",
    "class_weights = ['balanced', None]\n",
    "best_f1 = 0\n",
    "\n",
    "for est in n_estimators:\n",
    "    for depth in max_depth:\n",
    "        for wgt in class_weights:\n",
    "            clf = RandomForestClassifier(n_estimators=est, max_depth=depth, oob_score=True, class_weight=wgt)\n",
    "            clf.fit(X_train, y_train)\n",
    "            f1 = f1_score(y_train, np.argmax(clf.oob_decision_function_, 1))\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params = (est, depth, wgt)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best OOB F1: 0.7762376237623761\n",
      "Best params: (5000, 10, 'balanced')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best OOB F1: {}\".format(best_f1))\n",
    "print(\"Best params: {}\".format(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.88      0.86       103\n",
      "          1       0.83      0.78      0.80        76\n",
      "\n",
      "avg / total       0.84      0.84      0.84       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators=best_params[0], max_depth=best_params[1], class_weight=best_params[2])\n",
    "clf1.fit(X_train, y_train)\n",
    "test_predictions = clf1.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_imp = sorted(list(zip(X.columns, clf.feature_importances_)), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x112761160>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAExCAYAAAB71MlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkvgjIjomiT8iomOS+CMiOub/AxdQ9BgaSPKWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112761be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series([x[1] for x in feature_imp], index=[x[0] for x in feature_imp]).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's cool! As expected, gender played the biggest role of the variables in the dataset. I am surprised \"Deck\" didn't play a more substantial role. Perhaps there are just too many missing values for \"Deck\" for it to give our model much predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the average F1 was .84, I'm going to try another model. This time: Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 1000, 5000], 'max_depth': [1, 2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "clf = GradientBoostingClassifier()\n",
    "gridsearch = GridSearchCV(clf, {\"learning_rate\": [.1, .01, .001], \"n_estimators\": [100, 1000, 5000], \n",
    "                                \"max_depth\": [1, 2, 3]}, scoring='f1')\n",
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 5000}\n",
      "\n",
      "Classifcation Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.89      0.86       105\n",
      "          1       0.82      0.76      0.79        74\n",
      "\n",
      "avg / total       0.83      0.83      0.83       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "print(\"\\nClassifcation Report:\")\n",
    "print(classification_report(y_test, gridsearch.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting gave an average f1 of .83 which is about the same as our Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a Support Vector Machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981741573034\n"
     ]
    }
   ],
   "source": [
    "clf3 = SVC()\n",
    "clf3.fit(X_train, y_train)\n",
    "y_pred = clf3.predict(X_test)\n",
    "print(clf3.score(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a great score for SVM, but it performs worse on Kaggle than the Random Forest did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try naive bayes just for good measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total of 712 points : 294\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X, y).predict(X)\n",
    "print(\"Number of mislabeled points out of a total of %d points : %d\"\n",
    "       % (X_train.shape[0], (y != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes got only 59% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model was Random Forest. I use that for my Kaggle submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels=[\"Name\", \"PassengerId\", \"Cabin\", \"Ticket\"]\n",
    "X = Clean_Data(labels=labels, filename=\"test_titanic.csv\", test=True)\n",
    "y = clf1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"predictions.csv\", y, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
